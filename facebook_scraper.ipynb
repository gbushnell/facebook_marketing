{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WoodenPickleFBposts.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvB9rAY9TcJ8",
        "colab_type": "text"
      },
      "source": [
        "First, we need to obtain our data. We can use a nice FaceBook scraper to scrape the last posts in a usable format. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HlhVSVdRRAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e5f7e17f-c86c-4a81-df78-e9e80745909c"
      },
      "source": [
        "#install & load scraper\n",
        "!pip install facebook_scraper\n",
        "\n",
        "from facebook_scraper import get_posts\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: facebook_scraper in /usr/local/lib/python3.6/dist-packages (0.2.9)\n",
            "Requirement already satisfied: html2text<2021.0.0,>=2020.1.16 in /usr/local/lib/python3.6/dist-packages (from facebook_scraper) (2020.1.16)\n",
            "Requirement already satisfied: requests-html<0.11.0,>=0.10.0 in /usr/local/lib/python3.6/dist-packages (from facebook_scraper) (0.10.0)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.6/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.16.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.6/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (0.1.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.23.0)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.6/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.4.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.6/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (0.2.2)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.6/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.22.0)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from requests-html<0.11.0,>=0.10.0->facebook_scraper) (0.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.25.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->requests-html<0.11.0,>=0.10.0->facebook_scraper) (3.0.4)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.6/dist-packages (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.2.6)\n",
            "Requirement already satisfied: cssselect>0.7.9 in /usr/local/lib/python3.6/dist-packages (from pyquery->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.1.0)\n",
            "Requirement already satisfied: websockets<9.0,>=8.1 in /usr/local/lib/python3.6/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (8.1)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.4.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.6/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.48.2)\n",
            "Requirement already satisfied: pyee<8.0.0,>=7.0.1 in /usr/local/lib/python3.6/dist-packages (from pyppeteer>=0.0.14->requests-html<0.11.0,>=0.10.0->facebook_scraper) (7.0.2)\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from w3lib->requests-html<0.11.0,>=0.10.0->facebook_scraper) (1.15.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->requests-html<0.11.0,>=0.10.0->facebook_scraper) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S51OT_QUDB9",
        "colab_type": "text"
      },
      "source": [
        "**1. Lets first scrape the posts from the first 200 posts of their Facebook page.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_vD_JZ3SXuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scrape\n",
        "post_list = []\n",
        "\n",
        "for post in get_posts('woodenpickle120main', pages=200):\n",
        "  post_list.append(post)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LY7MaTXTbFA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "72539aff-c4fa-4514-ee1f-7b1e162359b0"
      },
      "source": [
        "#View the data \n",
        "print(post_list[0].keys())\n",
        "print(\"Number of Posts: {}\".format(len(post_list)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['post_id', 'text', 'post_text', 'shared_text', 'time', 'image', 'video', 'video_thumbnail', 'likes', 'comments', 'shares', 'post_url', 'link'])\n",
            "Number of Posts: 38\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJr6UXUlVSbZ",
        "colab_type": "text"
      },
      "source": [
        "**2. Lets clean up the list, keeping only Time, Image, Likes, Comments, Shares.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxTDhwHUVhpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "post_list_cleaned = []\n",
        "\n",
        "for post in post_list:\n",
        "  #create a list of indexes to keep\n",
        "  temp = []\n",
        "  indexes_to_keep = ['time', 'image', 'likes', 'comments', 'shares']\n",
        "  for key in indexes_to_keep:\n",
        "    temp.append(post[key])\n",
        "  post_list_cleaned.append(temp)\n",
        "\n",
        "#Remove image hyperlink, replace with 0, 1 & recast date\n",
        "for post in post_list_cleaned:\n",
        "  if post[1] == None:\n",
        "    post[1] = 0\n",
        "  else:\n",
        "    post[1] = 1\n",
        "  post[0] = post[0].date\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7yVnTuA_M9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#turn into a DataFrame\n",
        "fb_posts_df = pd.DataFrame(post_list_cleaned)\n",
        "fb_posts_df.columns = ['Date', 'image', 'likes', 'comments', 'shares']\n",
        "\n",
        "#import our POS data\n",
        "daily_sales_df = pd.read_csv('daily_sales.csv')\n",
        "\n",
        "#merge both sets of data\n",
        "combined_df = pd.merge(daily_sales_df, fb_posts_df, on='Date', how='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5FAWR2l17kO",
        "colab_type": "text"
      },
      "source": [
        "**3. Export data to CSV. The data will then be modeled in *R*.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n51uJguGwMei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combined_df.to_csv('data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2doDCg9xJhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10751f9e-3f19-4b06-fbf6-6b5a5b98409d"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.csv  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}